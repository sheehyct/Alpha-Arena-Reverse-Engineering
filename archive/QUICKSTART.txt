â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                   NOF1.AI SCRAPER - QUICK START GUIDE                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

STEP 1: INSTALL PLAYWRIGHT
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Open terminal/command prompt and run:

    pip install playwright
    playwright install chromium

This downloads the browser engine needed for scraping.


STEP 2: START THE SCRAPER
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

    python nof1_scraper.py

That's it! The scraper will:
âœ“ Check NOF1.AI every 2.5 minutes
âœ“ Save all ModelChat messages to nof1_data.db
âœ“ Skip duplicates automatically
âœ“ Log activity to nof1_scraper.log
âœ“ Run until you press Ctrl+C


STEP 3: MONITOR IN REAL-TIME (Optional)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Open a second terminal and run:

    python nof1_monitor.py

You'll see a live dashboard showing:
â€¢ Total messages collected
â€¢ Messages per model
â€¢ Recent activity feed
â€¢ Last scrape time

Refreshes every 10 seconds automatically.


STEP 4: ANALYZE THE DATA
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

After collecting data for a few hours/days:

    python nof1_analyzer.py --report

This creates deepseek_analysis.txt with:
â€¢ Most common trading phrases
â€¢ Entry signal patterns  
â€¢ Exit decision analysis
â€¢ Timeframe preferences
â€¢ Sample reasoning chains


COMMON COMMANDS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

View Statistics:
    python nof1_scraper.py --stats

Export to CSV:
    python nof1_scraper.py --export

Show Last 10 Messages:
    python nof1_monitor.py --tail 10

View Entry Signals:
    python nof1_analyzer.py --entries

Analyze Exit Patterns:
    python nof1_analyzer.py --exits

Compare All Models:
    python nof1_analyzer.py --compare


RECOMMENDED WORKFLOW
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Day 1:
1. Start scraper in background
2. Let it run for 24 hours to collect baseline data

Day 2:
1. Check stats: python nof1_scraper.py --stats
2. Generate first report: python nof1_analyzer.py --report
3. Review DeepSeek's entry signals

Day 3-7:
1. Continue scraping
2. Run analysis every 2-3 days
3. Look for recurring patterns in reasoning
4. Note confidence levels for successful trades

Week 2:
1. Export full dataset: python nof1_scraper.py --export
2. Build custom analysis in Excel/Python
3. Map patterns to your ThinkScript indicator


CUSTOMIZATION OPTIONS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Check every 3 minutes instead of 2.5:
    python nof1_scraper.py --interval 180

Use custom database location:
    python nof1_scraper.py --db /path/to/my_data.db

Monitor specific model only:
    python nof1_analyzer.py --model qwen3-max --entries


RUNNING IN BACKGROUND
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Linux/Mac (using screen):
    screen -S nof1
    python nof1_scraper.py
    # Press Ctrl+A then D to detach
    # Reattach later: screen -r nof1

Windows (run without console):
    pythonw nof1_scraper.py

Or use Task Scheduler to run on startup.


TROUBLESHOOTING
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

"Playwright not installed":
    pip install playwright
    playwright install chromium

"No messages found":
    Site structure may have changed. The scraper uses best-effort selectors
    and will grab visible text as fallback. Check nof1_scraper.log for details.

Database locked:
    Another process is using the database. Stop other instances:
    ps aux | grep nof1  # then kill [PID]

High CPU:
    Increase check interval:
    python nof1_scraper.py --interval 300


WHAT TO LOOK FOR IN DEEPSEEK'S REASONING
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Entry Signals:
â€¢ "momentum acceleration"
â€¢ "volume confirmation"
â€¢ "breakout above resistance"
â€¢ Specific confidence levels (0.7-0.9)

Risk Management:
â€¢ Stop loss placement logic
â€¢ Invalidation conditions
â€¢ Position sizing rules
â€¢ Leverage amounts (10x, 5x, etc.)

Exit Triggers:
â€¢ "invalidation triggered"
â€¢ "target reached"
â€¢ "momentum fading"
â€¢ Structural break conditions

Timeframes:
â€¢ Primary trend timeframe mentions
â€¢ Execution timeframe references
â€¢ Multi-timeframe confirmation

These patterns will directly inform your penny stock indicator parameters!


QUESTIONS?
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Check README.md for full documentation.
Review code comments in each .py file.
Check nof1_scraper.log for detailed activity logs.

Happy scraping! ğŸš€
